\chapter{Projeto do Serviço em Nuvem}\label{chp:serviconuvem}
Este capítulo possui a finalidade de projetar e implementar um serviço em nuvem acessível aos controladores locais da rede de sensores, de modo a alcançar o objetivo (ii) do trabalho. Os tópicos abordados neste capítulo englobam o método de troca de dados entre o controlador local e o servidor em nuvem, a interface de controle do usuário e a especificação de um algoritmo de aprendizagem específico para o domínio de controle de iluminação.


\section{Desenvolvimento do Algoritmo de Aprendizagem}
Nesta seção, detalha-se o processo de desenvolvimento de um algoritmo de aprendizagem para o domínio de controle de iluminação. O algoritmo recebe como entradas um conjunto de dados descrevendo o estado de sensores e atuadores, provenientes do controlador local, e produz como saídas regras de atuação, condicionais aos estados dos sensores.

\subsection{Formato de Entrada dos Dados}\label{subsec:formatoentrada}
No domínio selecionado para este trabalho, o dado de atuação relevante seria o estado da lâmpada a ser controlada. O objetivo do algoritmo, então, é prever o valor deste estado baseado nas leituras de outros sensores existentes na rede doméstica, tais como de luminosidade e presença. A Tabela \ref{tab:entrada_learning} ilustra o formato de entrada dos dados.

\begin{table}[h]
	\centering
	\caption{Formato dos dados de entrada para o algoritmo de aprendizagem}\smallskip
	\label{tab:entrada_learning}
	\includegraphics[width=0.5\textwidth]{tabelas/entrada_learning.pdf}
\end{table}

Observe que o problema em questão consiste em receber dados de treino, que representam o comportamento do usuário, e desenvolver um modelo que preveja o estado do atuador de forma fiel aos dados observados. Trata-se, portanto, de um problema de aprendizagem supervisionada, definido em \cite{james2014} como sendo a geração de um modelo que relaciona uma variável-alvo (no caso, o estado da lâmpada) com variáveis preditoras (presença, luminosidade, entre outros). O estado da lâmpada, então, é visto como uma classe associada a cada entrada do conjunto de dados, e o processo de aprendizagem supervisionado que infere esta classe para entradas não vistas anteriormente é denominado Classificação.

\subsection{Algoritmos de Classificação Existentes}\label{subsec:algclass}
Existem diversos algoritmos de classificação documentados na literatura, cada qual adotando uma abordagem distinta para geração de modelos e classificação de dados novos \cite{han2005, james2014}. A seguir serão descritos de forma sucinta três técnicas candidatas a serem utilizadas no processo de derivação de regras para este projeto.

\subsubsection{Indução por Árvore de Decisão}
O modelo de classificação gerado por esta técnica consiste em uma árvore de decisão, em que cada nó interno representa um teste a uma variável preditora, cada aresta representa uma saída do teste, e cada nó terminal (folha) indica a classe resultante. A Figura \ref{fig:exemplo_arvore} mostra o exemplo de uma árvore de decisão obtida por esta técnica. 

Neste exemplo, o conjunto de dados refere-se a consumidores de uma loja de eletrônicos, e as classes mostradas nos nós-folha indicam se um consumidor adquire ou não certo produto. No caso, uma das regras geradas pelo modelo diz que se o consumidor é jovem e estudante, então ele adquire o produto.

\begin{figure}[h]
	\centering
	\caption{Exemplo de modelo gerado pela técnica de Indução por Árvore de Decisão}
  \includegraphics[width=0.8\textwidth]{imagens/exemplo_arvore.png}
  \label{fig:exemplo_arvore}  
  
  Fonte: \cite{han2005}
\end{figure}

Existem diversas implementações desta técnica de classificação, tais como ID3, C4.5 e CART, que adotam uma estratégia \textit{greedy} e \textit{top-down} de construção da árvore. Cada uma dessas implementações efetua o particionamento dos dados de forma particular, efetuando seleção de variáveis por critérios tais como ganho de informação, razão de ganho ou índice Gini. As descrições dessas técnicas fogem do escopo deste trabalho, e podem ser encontradas em \cite{han2005}.

\subsubsection{Redes Neurais}
A técnica de aprendizagem por redes neurais foi inspirada pelos ramos da psicologia e neurobiologia, que buscaram modelar computacionalmente o comportamento de neurônios. Uma rede neural é composta por diversas unidades interconectadas arranjadas em camadas, conforme ilustra a Figura \ref{fig:elem_rede_neural}. 

Os dados de entrada do classificador são passados para as unidades da camada de entrada. Esses dados, então, são combinados linearmente através de pesos determinados nas interconexões e passados às unidades das camadas intermediárias, denominadas \textit{hidden layers}. As saídas da última camada intermediária são passadas às unidades da camada de saída, que define a classe resultante.

\begin{figure}[h]
	\centering
	\caption{Elementos de uma rede neural}
  \includegraphics[width=0.8\textwidth]{imagens/elem_rede_neural.png}
  \label{fig:elem_rede_neural}  
  
  Fonte: \cite{han2005}
\end{figure}

O processo de aprendizagem das redes neurais é computacionalmente caro e complexo, envolvendo um processo denominado \textit{backpropagation}. Este é um processo iterativo que consiste em alimentar os dados de treino na rede neural, obter a saída com o modelo corrente, e reajustar os pesos do modelo em ordem reversa, partindo das unidades da camada de saída.

No entanto, as redes neurais possuem a vantagem de possuírem alta tolerância a dados ruidosos, além de não requerer conhecimento da relação entre as classes a serem previstas e as variáveis preditoras \cite{han2005}.

\subsubsection{\textit{Support Vector Machines} (SVM)}
O SVM é uma técnica de classificação que se baseia na definição de um hiperplano ótimo para efetuar a segregação dos dados pertencentes às diferentes classes. No caso, o hiperplano ótimo seria o que provê maior margem entre os dados, conforme ilustra a Figura \ref{fig:svm_max_margin}. Neste exemplo, o conjunto de dados é bidimensional, e o hiperplano de separação é uma reta. Observe que das diversas retas possíveis mostradas à esquerda, seleciona-se a que resulta em maior margem, mostrada à direita.

\begin{figure}[h]
	\centering
	\caption{Retas candidatas para efetuar a segregação dos dados (esq.), e a reta ótima selecionada, que provê a maior margem no conjunto de dados}
  \includegraphics[width=0.8\textwidth]{imagens/svm_max_margin.png}
  \label{fig:svm_max_margin}  
  
  Fonte: \cite{james2014}
\end{figure}

A técnica de SVM se baseia nesta ideia de definir um plano de separação ótimo, mas efetua a adição de mais dimensões aos dados originais para lidar com situações de margens não-lineares. Este aumento na dimensionalidade dos dados é feito com base na utilização de \textit{kernels}. A descrição matemática deste processo está fora do escopo deste trabalho, e pode ser encontrado em \cite{james2014}.

\subsection{Considerações sobre a Escolha do Algoritmo}
A seção \ref{subsec:algclass} apresentou três algoritmos de classificação passíveis de serem aplicados no projeto. Conforme mencionado, cada algoritmo possui uma abordagem distinta na construção do modelo e na avaliação de entradas novas para efetuar a classificação, possuindo vantagens e desvantagens particulares. Esta seção lista as considerações adotadas para a seleção do algoritmo a ser utilizado na geração de regras.

O fator principal utilizado para selecionar o algoritmo de aprendizagem é a interpretabilidade do modelo gerado. Dentre as razões para a priorização deste fator, destaca-se a necessidade de o usuário ter capacidade de analisar as regras propostas pelo algoritmo, de modo a dar-lhe a escolha de aceitá-la ou recusá-la. Essa possibilidade é extremamente importante, levando-se em conta que os sensores utilizados em ambiente doméstico podem possuir imprecisões que resultem na geração de regras estatisticamente precisas, mas ainda assim indesejadas pelo usuário.

Nesse contexto, \cite{james2014} menciona haver um \textit{tradeoff} entre a flexibilidade e a interpretabilidade dos métodos de aprendizagem, como mostra a Figura \ref{fig:interpretabilidade_algoritmos}. Métodos flexíveis possuem alta capacidade de gerar modelos que se adaptem a dados de natureza complexa, mas tais modelos acabam sendo de difícil interpretação pelo usuário. 

\begin{figure}[h]
	\centering
	\caption{\textit{Tradeoff} entre flexibilidade e interpretabilidade de métodos de aprendizagem}
  \includegraphics[width=0.8\textwidth]{imagens/interpretabilidade_algoritmos.pdf}
  \label{fig:interpretabilidade_algoritmos}  
  
  Fonte: \cite{james2014}
\end{figure}

Note que, dentre as técnicas apresentadas, redes neurais e SVM possuem alta flexibilidade, permitindo gerar modelos para dados com variáveis cuja relação é desconhecida, a princípio (no caso das redes neurais), e para dados com fronteira de decisão não-linear (no caso do SVM). Entretanto, os modelos gerados por estas técnicas são pouco interpretáveis: redes neurais expõem um conjunto de pesos que processam os dados, de acordo com a topologia selecionada, e o SVM gera um hiperplano de separação.

No extremo oposto encontra-se a técnica de classificação por árvores de decisão. Este método é mais restritivo em termos de flexibilidade, mas gera modelos facilmente interpretáveis. De posse de um modelo como o da Figura \ref{fig:exemplo_arvore}, por exemplo, é intuitivo obter os fatores que influenciam na classificação das entradas.

Pelas razões mencionadas anteriormente, o algoritmo de classificação por árvore de decisão foi adotado para derivar regras de atuação. A seguir serão descritos os experimentos feitos com  dados de iluminação, englobando o preprocessamento dos dados e a aplicação do algoritmo de classificação propriamente dito.

\subsection{Coleta de Dados}
Conforme mencionado, o domínio de aplicação abordado para concepção de um algoritmo de aprendizagem de regras é o de controle de iluminação. Para iniciar os testes, é necessário ter em mãos um \textit{dataset} em formato similar ao descrito na seção \ref{subsec:formatoentrada}. Para obter tais dados de treino, os membros do grupo adquiriram sensores de presença PIR e de iluminação, associando-os a um Raspberry Pi, a fim de coletar dados nas respectivas residências. A Figura \ref{fig:montagem_coleta} mostra as montagens utilizadas para efetuar as coletas nas residências.

\begin{figure}[h]
	\centering
	\caption{Montagens experimentais para coleta de dados de iluminação}
	\smallskip
  \includegraphics[width=0.8\textwidth]{imagens/montagem_coleta.png}
  \label{fig:montagem_coleta}  
\end{figure}

Neste processo, os dados foram amostrados a cada minuto. Na primeira montagem, foi utilizado um botão para sinalizar o momento em que o interruptor foi acionado, devido à inviabilidade de conectar o interruptor existente no processo de coleta. Os dados coletados por esta montagem serão referidos por \textit{dataset} 1. Na segunda montagem, o estado do interruptor foi inferido posteriormente, de acordo com o horário do dia e da iluminação ambiente. Os dados coletados por esta montagem serão denominados \textit{dataset} 2. O \textit{timestamp}, mostrado na Tabela \ref{tab:entrada_learning}, foi registrado para cada amostra coletada, e consiste na representação POSIX do instante de coleta do dado.

\subsection{Experimentos para Derivação de Regras}
Como mencionado, o grupo pretende usar um algoritmo de classificação baseado em árvore de decisão para gerar as regras de atuação. Levando em conta a rotina associada aos dados de treino coletados, o grupo espera, idealmente, que as seguintes regras sejam derivadas:
\begin{itemize}
	\item Acenda a luz quando há alguém no ambiente, e a iluminação no local é baixa;
	\item Apague a luz quando não há ninguém no ambiente
\end{itemize}

Para a geração das árvores de decisão, o grupo usou a ferramenta Rattle \footnote{Disponível em \url{http://rattle.togaware.com/}.}, que utiliza um algoritmo recursivo \textit{top-down} \cite{williams2011} implementado na biblioteca \texttt{rpart} \footnote{Documentação disponível em \url{https://cran.r-project.org/web/packages/rpart/index.html}}. O objetivo, nesta seção, é estudar modos de preprocessamento dos dados utilizados pelo algoritmo, e analisar a qualidade das regras criadas.

\subsubsection{Utilização de dados \textit{raw}}
A primeira tentativa de geração de regras foi feita alimentando o algoritmo de geração do modelo sem efetuar nenhum tipo de preprocessamento dos dados. Os resultados obtidos estão apresentados na Figura \ref{fig:teste_1}, para cada \textit{dataset} utilizado. Para auxiliar na interpretabilidade dos dados, tenha em mente que valores de luminância na ordem de 40 lx correspondem a um ambiente noturno, com uma lâmpada acesa.

\begin{figure}[hp]
	\caption{Árvores de decisão geradas sem nenhum preprocessamento de dados.}
	\smallskip
	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/1_h.png}
  \end{subfigure}
  	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/1_r.png}
  \end{subfigure}
  \label{fig:teste_1}  
\end{figure}

Observe que, no primeiro caso, o algoritmo tenta prever o estado da lâmpada baseado unicamente nos dados de iluminação ambiente, ao passo que no segundo, dados de presença também são utilizados. No entanto, a partir das regras criadas, é evidente que o algoritmo está prevendo qual o estado corrente da lâmpada, dados os parâmetros de entrada de luminância e presença. Por exemplo, uma das regras criadas diz que se o nível de luminosidade do ambiente for menor que 39, então a lâmpada está apagada.

Para fins de criação de regras, o interesse maior está em identificar o estado em que ocorreu uma mudança no estado da lâmpada. Para tanto, torna-se necessário efetuar um preprocessamento dos dados para evidenciar essas mudanças no \textit{dataset}.

\subsubsection{Adição de um campo de Ação}
Nesta tentativa, foi efetuado um passo de preprocessamento adicionando uma coluna indicando a ação tomada no instante. Por exemplo, se em um dado instante a lâmpada está apagada, mas no seguinte ela está acesa, então o campo "Ação" assume valor "1", indicando que a lâmpada foi acesa. Analogamente, se a lâmpada está acesa em um dado instante e no seguinte ela está apagada, então o campo "Ação" assume valor "-1", indicando que ela foi apagada. Caso o estado da lâmpada seja o mesmo em dois instantes de tempo consecutivos, o campo "Ação" assume valor "0", indicando ausência de ação.

Efetuando este tratamento, o algoritmo não produziu nenhum resultado, não sendo capaz de criar regras em ambos os \textit{datasets}. Uma análise mais profunda mostrou a razão disso: o número de pontos em que não houve ação é ordens de grandeza maior do que os pontos em que houve ação (cerca de 400 vezes mais pontos no primeiro dataset, e 300 no segundo). 

\subsubsection{Eliminação dos pontos sem ação} \label{subsubsec:elim_pts_sem_acao}
Esta tentativa buscou explorar a eficácia do algoritmo caso pontos sem ação (Ação=0) fossem eliminados. Os gráficos apresentados na Figura \ref{fig:teste_3} mostram as árvores de decisão geradas nesta tentativa.

\begin{figure}[hp]
	\caption{Árvores de decisão geradas mantendo somente pontos com ação tomada.}
	\smallskip
	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/3_h.png}
  \end{subfigure}
  	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/3_r.png}
  \end{subfigure}
  \label{fig:teste_3}  
\end{figure}

Observe que as regras geradas ditam que a luz seja apagada, caso ela esteja acesa, e vice-versa. De fato, do universo de pontos coletados neste item, é óbvio que a luz sempre é apagada quando ela está acesa, e ela sempre é acesa quando está apagada. Ocorre que a eliminação dos dados de Ação=0, apesar de resolver o problema de desbalanceamento, introduziu uma perda de informação significativa. Ocorre que, em diversos momentos em que a luz está acesa, ela não é apagada. A manutenção de tais pontos, pois, se mostra imprescindível para a geração de regras coerentes.

\subsubsection{Balanceamento do \textit{dataset}}
Conforme mencionado, o \textit{dataset} em questão é extremamente desbalanceado, com uma quantidade de entradas com classe Ação=0 ordens de grandeza maior que entradas das demais classes. Conforme mencionado em \cite{han2005}, dentre as técnicas utilizadas para se lidar com problemas de classificação desbalanceados estão o \textit{undersampling} da classe majoritária e o \textit{oversampling} da classe minoritária. Neste teste, a primeira técnica será adotada para reduzir a quantidade de entradas da classe Ação=0.

O \textit{undersample} foi efetuado selecionando-se uma quantidade de pontos da classe majoritária de forma aleatória. A Figura \ref{fig:teste_4} mostra as árvores de decisão geradas nesta tentativa.

\begin{figure}[hp]
	\caption{Árvores de decisão geradas efetuando \textit{undersample} da classe majoritária.}
	\smallskip
	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/4_h.png}
  \end{subfigure}
  	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/4_r.png}
  \end{subfigure}
  \label{fig:teste_4}  
\end{figure}

No \textit{dataset} 1, as regras produzidas foram:
\begin{itemize}
	\item Apague a luz quando ela estiver acesa ($light\_on >= 0.5$)
	\item Acenda a luz quando ela estiver apagada e a iluminação ambiente estiver entre 0.42 e 82
	\item Não faça nada caso contrário
\end{itemize}
No caso do segundo \textit{dataset}, as regras produzidas foram:
\begin{itemize}
	\item Apague a luz quando ela estiver acesa ($light\_on >= 0.5$)
	\item Acenda a luz quando ela estiver apagada, alguém estiver no quarto e a iluminação ambiente for menor que 24
	\item Não faça nada, caso contrário
\end{itemize}

Como foi efetuado uma amostragem aleatória em todos os pontos de não ação, reproduzimos esse teste diversas vezes, e as árvores resultantes são as que ocorriam com mais frequência nos testes. Em ambas as árvores, observa-se que ele derivou a regra para apagar a luz sempre que ela esteja acesa, e apenas no segundo \textit{dataset} utilizou a presença no caso de acender a luz.

Analisando o \textit{dataset}, observa-se que acontece de o usuário acender a luz antes da presença ser detectada e também de apagá-la ainda sob alcance do sensor de presença. Ou seja, o usuário deixa o ambiente quando apaga a luz e o frequenta quando a acende, e essa informação não é representada tomando unicamente a leitura instantânea do sensor de presença.

\subsubsection{Consideração de médias temporais dos dados}
Com o intuito de capturar o estado do ambiente associado à tomada de uma ação, testou-se a utilização de uma média temporal de $n$ pontos para a presença, em vez de utilizar uma única medida instantânea. Deste modo, para um dado instante, o valor da presença é a média dos $n$ valores subsequentes, arranjados de forma temporal. Efetuar este tipo de processamento faz com que os \textit{datasets} reflitam o estado do ambiente após a tomada da ação, contribuindo para a geração de regras mais precisas. No entanto, há a necessidade de se conhecer a natureza dos dados coletados para que este tipo de processamento faça sentido, tornando este tratamento específico para a aplicação descrita de controle de iluminação.

A Figura \ref{fig:teste_5_1} mostra árvores de decisão geradas para o \textit{dataset} 1, ao passo que a Figura \ref{fig:teste_5_2} mostra as geradas para o \textit{dataset} 2. Nestes modelos, foi utilizado $n=10$. Devido à natureza aleatória do \textit{undersampling}, as duas árvores apresentadas em cada figura foram geradas frequentemente.

\begin{figure}[hp]
	\caption{Árvores de decisão geradas para o \textit{dataset} 1 tomando a média temporal da presença, com $n=10$.}
	\smallskip
	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/5_h_1.png}
  \end{subfigure}
  	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/5_h_2.png}
  \end{subfigure}
  \label{fig:teste_5_1}  
\end{figure}

\begin{figure}[hp]
	\caption{Árvores de decisão geradas para o \textit{dataset} 2 tomando a média temporal da presença, com $n=10$.}
	\smallskip
	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/5_r_1.png}
  \end{subfigure}
  	\begin{subfigure}{\textwidth}
		\centering
  	\includegraphics[width=0.8\textwidth]{imagens/teste_learning/5_r_2.png}
  \end{subfigure}
  \label{fig:teste_5_2}  
\end{figure}

Observe que os resultados obtidos são similares para os dois \textit{datasets}. Analisando a primeira árvore da Figura \ref{fig:teste_5_1}, observa-se que as regras geradas foram:
\begin{itemize}
	\item Apague a luz quando ela estiver acesa e não houver ninguém no ambiente;
	\item Acenda a luz quando ela estiver apagada, houver presença no ambiente e o nível de luminosidade for menor que 45;
	\item Não faça nada caso contrário.
\end{itemize}
No caso da segunda árvore da Figura \ref{fig:teste_5_1}, tem-se as regras:
\begin{itemize}
	\item Apague a luz quando ela estiver acesa;
	\item Acenda a luz quando ela estiver apagada, houver presença no ambiente e o nível de luminosidade for menor que 73;
	\item Não faça nada caso contrário.
\end{itemize}

Observe que a primeira árvore obtida gerou regras ótimas, levando em conta os \textit{datasets} utilizados. A segunda, no entanto, ainda sugeria regras que simplesmente apagavam a luz quando ela estivesse acesa. Este problema é similar ao obtido no teste \ref{subsubsec:elim_pts_sem_acao}, e provavelmente se deve ao fato de não terem sido escolhidos pontos suficientes da classe Ação=0 no processo de \textit{undersampling}.